---
title: "p8105_hw6_qw2331"
output: github_document
---

```{r setup, echo = FALSE, message = FALSE}
library(tidyverse)
library(modelr)
library(patchwork)
library(plyr)

knitr::opts_chunk$set(
  fig.width = 10,
  fig.asp = .6,
  out.width = "90%",
  message = FALSE,
  warning = FALSE
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(1234)
```


## Problem 1

### 1.1 Load data
```{r}
baby_bwt_raw <- 
  read_csv("./data/birthweight.csv")
```


### 1.2 Clean data
```{r}
# Briefly overview data type for each column
sapply(baby_bwt_raw, class)

# Convert numeric to factor
race_map <- 
  c(`1` = "White", `2` = "Black", `3` = "Asian", `4` = "Puerto Rican", `8` = "Other", `9` = "Unkown")

baby_bwt_df <- 
  baby_bwt_raw %>% 
  mutate(
    babysex = factor(recode(babysex, `1` = "male", `2` = "female")),
    malform = factor(recode(malform, `0` = "absent", `1` = "present")),
    frace = as.factor(revalue(as.character(frace), race_map)),
    mrace = as.factor(revalue(as.character(mrace), race_map))
  ) %>% 
  distinct()

# Check missing values
baby_bwt_df %>% 
  is.na() %>% 
  colSums()
```


### 1.3 Propose a regression model

**1.3.1 Distribution of the target variable `bwt`**
```{r}
baby_bwt_df %>% 
  ggplot(aes(bwt)) + 
  geom_histogram(aes(y = ..density..), fill = "orange") +
  geom_density() + 
  labs(
    title = "Distribution of birthweight",
    x = "Birthweight (grams)",
    y = "Density"
  )
```

**1.3.2 Summary statistics and check outliers**
```{r}
# Check for missing values
# Or a brief data review using function str()
summary(baby_bwt_df)

# Check outliers using boxplot
pivotdata <- 
  baby_bwt_df %>% 
  select(2:3, 5:6, 8, 10:12, 17:20) %>% 
  pivot_longer(
    everything(),
    names_to = "variable",
    values_to = "value"
  )

pivotdata %>% 
  ggplot(aes(factor(variable), value)) + 
  geom_boxplot(
    aes(color = variable), 
    show.legend = FALSE, outlier.size = .8) + 
  facet_wrap(~variable, scale = "free") + 
  labs(
    title = "Boxplots of 12 numeric variables",
    x = "Variable",
    y = "Value"
  )
```

**1.3.3 Correlation Matrix**
```{r}
# Create a correlation matrix
cordata <- 
  baby_bwt_df %>% 
  select(2:6, 8, 10:12, 17:18, 20) %>% 
  cor() %>% 
  round(3)

ggcorrplot::ggcorrplot(
  cordata, type = "lower", hc.order = TRUE, lab = TRUE, lab_size = 3) + 
  guides(
    fill = guide_legend(title = "Pearson\nCorrelation")
  )
```

**1.3.4 Regression model and diagnostics**
```{r}
# Fit model
baby_bwt_df <- 
  baby_bwt_df %>% 
  select(babysex, bhead, blength, bwt, gaweeks)

# Choose variables simply based on previous analysis
mod1 <- lm(bwt ~ bhead + blength, data = baby_bwt_df)

# Present output
mod1 %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)

# Diagnostics
# Residuals vs. Fits plot
res_fit_plot <-   
  baby_bwt_df %>% 
  add_residuals(mod1) %>% 
  add_predictions(mod1) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(size = 1.5, alpha = .4) + 
  geom_hline(yintercept = 0, linetype = "dotted") + 
  labs(
    title = "Residuals vs. Fitted",
    x = "Fitted values",
    y = "Residuals"
  )

# QQ-plot
qq_plot <- 
  baby_bwt_df %>% 
  ggplot(aes(sample = bwt)) + 
  geom_qq(alpha = .4) + 
  geom_qq_line(linetype = "dotted") + 
  labs(
    title = "Normal Q-Q",
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  )

res_fit_plot + qq_plot
```

**Modeling process:**  
+ Check the distribution of the target variable `bwt`, which follows normal distribution  
+ Check missing values and outliers for numeric variables  
+ Visualize the correlation matrix and choose variables `bhead` and `blength` intuitively as these two variables reflect high correlations with the target variable `bwt`  
+ Build a linear regression model with the main effects of these two only  
+ Model diagnosis using residual vs. fitted values plot and qq-plot

**1.3.5 Compare with the other two models using CV**
```{r}
# Split training/testing 100 times
baby_bwt_cv_df <- 
  crossv_mc(baby_bwt_df, 1000)

# Fit the previous model and the other two
# Use RMSE to compare the predictions
baby_bwt_cv_df <- 
  baby_bwt_cv_df %>% 
  mutate(
    mod1 = map(train, ~lm(bwt ~ bhead + blength, data = .x)),
    mod2 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    mod3 = map(train, ~lm(bwt ~ bhead + blength + babysex + 
                         bhead * blength + bhead * babysex + blength * babysex +
                         bhead * blength * babysex, data = .x))
  ) %>% 
  mutate(
    rmse_mod1 = map2_dbl(mod1, test, ~rmse(model = .x, data = .y)),
    rmse_mod2 = map2_dbl(mod2, test, ~rmse(model = .x, data = .y)),
    rmse_mod3 = map2_dbl(mod3, test, ~rmse(model = .x, data = .y))
  )

baby_bwt_cv_df %>% 
  select(c(7:9)) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse, color = model)) + 
  geom_violin() + 
  labs(
    title = "Model Comparison",
    x = "Model",
    y = "Rmse"
  )
```

From the violin plot, the second model is ruled out as its highest RMSE. Although the RMSE of the first model is similar with the third one and cannot be differentiated visually, the first model is still preferred based on the "parsimony rule".

## Problem 2

### 2.1 Load data
```{r}
weather_df <-  
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

### 2.2 Bootstrapping and visualization
```{r}
# Write a function
boot_sample <- function(df) {
  sample_frac(df, size = 1, replace = TRUE)
}

# Resample data 5000 times
bootstrap_df <- 
  tibble(
    strap_number = c(1:5000),
    strap_sample = rerun(5000, boot_sample(weather_df))
  )

# Plot distribution of the two estimates
# Choose r-squared as the model's simplicity
bootstrap_results <- 
  bootstrap_df %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x)),
    results1 = map(models, broom::glance),
    results2 = map(models, broom::tidy)
  )

bootstrap_results <- 
  bootstrap_results %>% 
  # Select r squared
  unnest(results1) %>% 
  select(strap_number, r.squared, results2) %>% 
  # Log the product of intercept and slope
  unnest(results2) %>% 
  group_by(strap_number) %>% 
  mutate(
    estimate2 = lead(estimate, n = 1),
    log_result = log10(estimate * estimate2)
  ) %>% 
  filter(term == "(Intercept)") %>% 
  select(strap_number, r.squared, log_result)

bootstrap_results %>% 
  pivot_longer(
    2:3,
    names_to = "quantity",
    values_to = "estimate"
  ) %>% 
  ggplot(aes(x = estimate, fill = quantity)) + 
  geom_histogram(bins = 30, show.legend = FALSE) + 
  facet_grid(~ quantity, scales = "free") + 
  labs(
    title = "Distribution of two estimated quantities",
    x = "Estimate",
    y = "Count"
  )
```

As the plots shown, the estimate of the log result is around 0.875 while the estimate of r squared is nearly 0.916.

### 2.3 Compute confidence intervals 
```{r}
bootstrap_results %>%  
  as_tibble() %>% 
  select(-1) %>% 
  map_df(~ quantile(., probs = c(.025, .975))) %>% 
  mutate(name = c("R.squared", "Log result")) %>% 
  select(3, 1, 2) %>% 
  knitr::kable(digits = 3)
```

From the above calculation, the 95% confidence interval for $\hat r^2$ is (0.894, 0.927) and (0.853, 0.894) for $\log(\hat \beta_0 * \hat \beta_1)$.